import streamlit as st
import google.generativeai as genai
import tempfile
import os
import time

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="YouTube Shorts AI Assistant",
    page_icon="ğŸ¬",
    layout="wide"
)

# ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ¬ YouTube Shorts æŠ•ç¨¿æ”¯æ´ AIã‚¢ãƒ—ãƒª")
st.markdown("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€GeminiãŒã‚¿ã‚¤ãƒˆãƒ«ãƒ»èª¬æ˜ãƒ»ã‚¿ã‚°ã‚’ææ¡ˆã—ã€å£æ‰“ã¡ç›¸è«‡ã‚‚ã§ãã¾ã™ã€‚")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼: APIã‚­ãƒ¼è¨­å®š
with st.sidebar:
    st.header("è¨­å®š")
    api_key = st.text_input("Gemini API Key", type="password")
    st.markdown("[APIã‚­ãƒ¼ã®å–å¾—ã¯ã“ã¡ã‚‰](https://aistudio.google.com/app/apikey)")
    
    st.divider()
    st.markdown("""
    **ä½¿ã„æ–¹:**
    1. APIã‚­ãƒ¼ã‚’å…¥åŠ›
    2. MP4å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    3. ã€Œè§£æãƒ»ç”Ÿæˆã™ã‚‹ã€ã‚’ã‚¯ãƒªãƒƒã‚¯
    4. çµæœã‚’ã‚³ãƒ”ãƒ¼ã—ã¦YouTubeã¸
    5. æ°—ã«å…¥ã‚‰ãªã„å ´åˆã¯ãƒãƒ£ãƒƒãƒˆã§ç›¸è«‡
    """)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "analysis_result" not in st.session_state:
    st.session_state.analysis_result = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "uploaded_file_name" not in st.session_state:
    st.session_state.uploaded_file_name = None

# Geminiã®è¨­å®šé–¢æ•°
def configure_gemini(api_key):
    genai.configure(api_key=api_key)

# å‹•ç”»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†
uploaded_file = st.file_uploader("ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»(MP4)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp4"])

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
if uploaded_file and api_key:
    configure_gemini(api_key)
    
    # å‹•ç”»ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚«ãƒ©ãƒ åˆ†ã‘ï¼‰
    col1, col2 = st.columns([1, 2])
    with col1:
        st.video(uploaded_file)
    
    with col2:
        st.info("å‹•ç”»ãŒã‚»ãƒƒãƒˆã•ã‚Œã¾ã—ãŸã€‚è§£æãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
        
        # è§£æãƒœã‚¿ãƒ³
        if st.button("ğŸš€ è§£æãƒ»æ¡ˆã‚’ç”Ÿæˆã™ã‚‹", type="primary"):
            try:
                with st.spinner('å‹•ç”»ã‚’Geminiã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...'):
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
                    tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                    tfile.write(uploaded_file.read())
                    video_path = tfile.name
                    tfile.close()

                    # Geminiã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                    video_file = genai.upload_file(path=video_path)
                    
                    # å‡¦ç†å¾…ã¡
                    while video_file.state.name == "PROCESSING":
                        time.sleep(2)
                        video_file = genai.get_file(video_file.name)

                    if video_file.state.name == "FAILED":
                        st.error("å‹•ç”»ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    else:
                        st.session_state.uploaded_file_name = video_file.name
                        
                        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
                        prompt = """
                        ã‚ãªãŸã¯ãƒ—ãƒ­ã®YouTubeã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
                        ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå‹•ç”»ã¯YouTubeã‚·ãƒ§ãƒ¼ãƒˆç”¨ã§ã™ã€‚
                        å‹•ç”»ã®å†…å®¹ã‚’è¦–è¦šçš„ãƒ»è´è¦šçš„ã«æ·±ãåˆ†æã—ã€ãƒã‚ºã‚‹ãŸã‚ã®ä»¥ä¸‹ã®è¦ç´ ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
                        
                        å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
                        ã€ã‚¿ã‚¤ãƒˆãƒ«ã€‘ (ã‚­ãƒ£ãƒƒãƒãƒ¼ã§30æ–‡å­—ä»¥å†…)
                        ã€èª¬æ˜æ¬„ã€‘ (ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’å«ã‚ãŸSEOã«å¼·ã„èª¬æ˜æ–‡)
                        ã€ã‚¿ã‚°ã€‘ (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§10å€‹ç¨‹åº¦)
                        
                        åˆ†æã®æ ¹æ‹ ã‚‚å°‘ã—æ·»ãˆã¦ãã ã•ã„ã€‚
                        """

                        with st.spinner('AIãŒå‹•ç”»ã‚’è¦‹ã¦ã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è€ƒãˆã¦ã„ã¾ã™...'):
                            model = genai.GenerativeModel('gemini-1.5-flash')
                            response = model.generate_content([video_file, prompt])
                            st.session_state.analysis_result = response.text
                            
                            # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚ã‚‹ï¼‰
                            st.session_state.chat_history = [
                                {"role": "user", "content": "ã“ã®å‹•ç”»ã®åˆ†æã¨ææ¡ˆã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"},
                                {"role": "model", "content": response.text}
                            ]
                        
                        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                        os.unlink(video_path)

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
if st.session_state.analysis_result:
    st.divider()
    st.header("ğŸ“ ç”Ÿæˆçµæœ")
    
    # çµæœã‚’è¦‹ã‚„ã™ãè¡¨ç¤º
    st.markdown(st.session_state.analysis_result)
    
    # ã‚³ãƒ”ãƒ¼ç”¨ã‚¨ãƒªã‚¢ï¼ˆst.codeã‚’ä½¿ã†ã¨ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ã‚³ãƒ”ãƒ¼ã§ãã¾ã™ï¼‰
    with st.expander("ã‚³ãƒ”ãƒ¼ç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢", expanded=True):
        st.text_area("å…¨ã‚³ãƒ”ãƒ¼ç”¨", value=st.session_state.analysis_result, height=300)

    # å‚™è€ƒæ¬„
    st.divider()
    st.subheader("ğŸ“Œ å‚™è€ƒãƒ»ãƒ¡ãƒ¢")
    remarks = st.text_area("æŠ•ç¨¿æ—¥æ™‚ã‚„ãƒªãƒ³ã‚¯ã€ç‰¹è¨˜äº‹é …ãªã©ã‚’ã“ã“ã«ãƒ¡ãƒ¢ã§ãã¾ã™ã€‚", height=100)

    # å£æ‰“ã¡æ©Ÿèƒ½
    st.divider()
    st.header("ğŸ¤– å£æ‰“ã¡ãƒ»ç›¸è«‡ãƒãƒ£ãƒƒãƒˆ")
    st.markdown("ææ¡ˆã•ã‚ŒãŸå†…å®¹ãŒæ°—ã«å…¥ã‚‰ãªã„å ´åˆã‚„ã€å¾®èª¿æ•´ã—ãŸã„å ´åˆã¯ã“ã“ã§ç›¸è«‡ã—ã¦ãã ã•ã„ã€‚\n(ä¾‹: ã€Œã‚‚ã£ã¨å¥³å­é«˜ç”Ÿå‘ã‘ã«ã—ã¦ã€ã€Œã‚¿ã‚¤ãƒˆãƒ«ã‚’3æ¡ˆå‡ºã—ã¦ã€)")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    for message in st.session_state.chat_history:
        if message["role"] != "system": # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯éš ã™å ´åˆ
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    if prompt := st.chat_input("AIã«æŒ‡ç¤ºãƒ»ç›¸è«‡ã™ã‚‹..."):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’è¡¨ç¤º
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.chat_history.append({"role": "user", "content": prompt})

        # Geminiã¸ã®å•ã„åˆã‚ã›
        try:
            model = genai.GenerativeModel('gemini-1.5-flash')
            # éå»ã®å±¥æ­´ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦æ¸¡ã™
            chat = model.start_chat(history=st.session_state.chat_history)
            
            with st.spinner("è€ƒãˆä¸­..."):
                response = chat.send_message(prompt)
                
            with st.chat_message("model"):
                st.markdown(response.text)
            
            st.session_state.chat_history.append({"role": "model", "content": response.text})
            
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

elif not api_key:
    st.warning("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰Gemini APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")